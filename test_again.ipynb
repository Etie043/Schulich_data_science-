{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etiem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - loss: 8941.5947 - mean_absolute_error: 88.0950 - val_loss: 7557.6807 - val_mean_absolute_error: 85.6930\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8457.0938 - mean_absolute_error: 86.7262 - val_loss: 7537.5928 - val_mean_absolute_error: 85.5794\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8340.0156 - mean_absolute_error: 86.0946 - val_loss: 7517.6045 - val_mean_absolute_error: 85.4657\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 8153.7505 - mean_absolute_error: 84.8097 - val_loss: 7497.9717 - val_mean_absolute_error: 85.3534\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 8372.0420 - mean_absolute_error: 86.2722 - val_loss: 7478.6997 - val_mean_absolute_error: 85.2429\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8475.1553 - mean_absolute_error: 86.0295 - val_loss: 7459.2559 - val_mean_absolute_error: 85.1309\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8579.9463 - mean_absolute_error: 86.2455 - val_loss: 7439.2935 - val_mean_absolute_error: 85.0155\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8453.5420 - mean_absolute_error: 85.8448 - val_loss: 7418.5728 - val_mean_absolute_error: 84.8952\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8547.6426 - mean_absolute_error: 86.7994 - val_loss: 7397.0381 - val_mean_absolute_error: 84.7699\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8541.7734 - mean_absolute_error: 86.0936 - val_loss: 7374.2759 - val_mean_absolute_error: 84.6371\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8623.1631 - mean_absolute_error: 86.8869 - val_loss: 7349.4629 - val_mean_absolute_error: 84.4923\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8313.4355 - mean_absolute_error: 85.4515 - val_loss: 7322.5815 - val_mean_absolute_error: 84.3353\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8491.4844 - mean_absolute_error: 85.7982 - val_loss: 7293.6934 - val_mean_absolute_error: 84.1663\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 8267.4082 - mean_absolute_error: 84.8809 - val_loss: 7262.6016 - val_mean_absolute_error: 83.9840\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7702.7466 - mean_absolute_error: 82.3702 - val_loss: 7229.0874 - val_mean_absolute_error: 83.7871\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8125.3999 - mean_absolute_error: 83.9665 - val_loss: 7192.2939 - val_mean_absolute_error: 83.5707\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8237.5596 - mean_absolute_error: 84.6662 - val_loss: 7152.2983 - val_mean_absolute_error: 83.3350\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7855.2607 - mean_absolute_error: 83.1318 - val_loss: 7109.3652 - val_mean_absolute_error: 83.0812\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8052.1802 - mean_absolute_error: 83.4875 - val_loss: 7063.0547 - val_mean_absolute_error: 82.8063\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7770.3745 - mean_absolute_error: 82.7831 - val_loss: 7014.0659 - val_mean_absolute_error: 82.5145\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7714.2227 - mean_absolute_error: 82.2347 - val_loss: 6961.9951 - val_mean_absolute_error: 82.2030\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7222.1548 - mean_absolute_error: 79.7431 - val_loss: 6906.3960 - val_mean_absolute_error: 81.8690\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7594.3867 - mean_absolute_error: 81.4035 - val_loss: 6847.0381 - val_mean_absolute_error: 81.5109\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 7496.3530 - mean_absolute_error: 80.6281 - val_loss: 6784.0684 - val_mean_absolute_error: 81.1292\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6963.6646 - mean_absolute_error: 78.8101 - val_loss: 6717.6191 - val_mean_absolute_error: 80.7243\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7578.0649 - mean_absolute_error: 81.7819 - val_loss: 6646.7891 - val_mean_absolute_error: 80.2907\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6936.5352 - mean_absolute_error: 78.4193 - val_loss: 6572.1655 - val_mean_absolute_error: 79.8307\n",
      "Epoch 28/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6777.4028 - mean_absolute_error: 77.5020 - val_loss: 6493.3828 - val_mean_absolute_error: 79.3420\n",
      "Epoch 29/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7019.0391 - mean_absolute_error: 78.3312 - val_loss: 6410.3506 - val_mean_absolute_error: 78.8237\n",
      "Epoch 30/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7393.3765 - mean_absolute_error: 79.9851 - val_loss: 6322.6279 - val_mean_absolute_error: 78.2723\n",
      "Epoch 31/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6732.2695 - mean_absolute_error: 77.0043 - val_loss: 6231.0703 - val_mean_absolute_error: 77.6920\n",
      "Epoch 32/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7088.5518 - mean_absolute_error: 78.0266 - val_loss: 6134.1504 - val_mean_absolute_error: 77.0730\n",
      "Epoch 33/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6842.6582 - mean_absolute_error: 76.5846 - val_loss: 6033.0254 - val_mean_absolute_error: 76.4210\n",
      "Epoch 34/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6663.6816 - mean_absolute_error: 75.5959 - val_loss: 5926.8022 - val_mean_absolute_error: 75.7299\n",
      "Epoch 35/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5809.7349 - mean_absolute_error: 72.1463 - val_loss: 5816.0215 - val_mean_absolute_error: 75.0009\n",
      "Epoch 36/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5898.6440 - mean_absolute_error: 71.5108 - val_loss: 5701.8916 - val_mean_absolute_error: 74.2422\n",
      "Epoch 37/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6142.2134 - mean_absolute_error: 72.1915 - val_loss: 5582.6411 - val_mean_absolute_error: 73.4412\n",
      "Epoch 38/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6008.6782 - mean_absolute_error: 71.2439 - val_loss: 5458.5762 - val_mean_absolute_error: 72.5977\n",
      "Epoch 39/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5634.7422 - mean_absolute_error: 69.6473 - val_loss: 5330.4644 - val_mean_absolute_error: 71.7154\n",
      "Epoch 40/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5834.3701 - mean_absolute_error: 70.6977 - val_loss: 5197.1465 - val_mean_absolute_error: 70.7854\n",
      "Epoch 41/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5831.7666 - mean_absolute_error: 69.8704 - val_loss: 5060.2227 - val_mean_absolute_error: 69.8163\n",
      "Epoch 42/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5279.4414 - mean_absolute_error: 67.2607 - val_loss: 4918.9336 - val_mean_absolute_error: 68.8012\n",
      "Epoch 43/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5298.9668 - mean_absolute_error: 67.4932 - val_loss: 4773.2295 - val_mean_absolute_error: 67.7378\n",
      "Epoch 44/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4953.9136 - mean_absolute_error: 64.9434 - val_loss: 4623.7002 - val_mean_absolute_error: 66.6277\n",
      "Epoch 45/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4949.9624 - mean_absolute_error: 63.9889 - val_loss: 4472.1934 - val_mean_absolute_error: 65.4829\n",
      "Epoch 46/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4648.2056 - mean_absolute_error: 62.3260 - val_loss: 4316.6348 - val_mean_absolute_error: 64.2848\n",
      "Epoch 47/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4416.6045 - mean_absolute_error: 61.3894 - val_loss: 4159.3242 - val_mean_absolute_error: 63.0484\n",
      "Epoch 48/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4397.5034 - mean_absolute_error: 60.1852 - val_loss: 3998.3572 - val_mean_absolute_error: 61.7568\n",
      "Epoch 49/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 4237.0757 - mean_absolute_error: 58.8345 - val_loss: 3835.0952 - val_mean_absolute_error: 60.4165\n",
      "Epoch 50/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3915.3198 - mean_absolute_error: 57.0250 - val_loss: 3670.8887 - val_mean_absolute_error: 59.0341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\n",
      "Mean Absolute Error (MAE):\n",
      "63.049553923762254\n"
     ]
    }
   ],
   "source": [
    "# starter notebook content:\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/Etie043/Schulich_data_science-/refs/heads/main/Recipe%20Reviews%20and%20User%20Feedback%20Dataset.csv')\n",
    "\n",
    "# Aggregate data by recipe -- EXAMPLE (adjust as needed)\n",
    "agg_data = data.groupby('recipe_code').agg({\n",
    "    'stars': 'mean',  # Average rating\n",
    "    'comment_id': 'count',  # Count of comments as a proxy for engagement\n",
    "    'best_score': 'mean'  # Average best score\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns to reflect theiry_predeaning\n",
    "agg_data.rename(columns={\n",
    "    'stars': 'avg_stars', \n",
    "    'comment_id': 'comment_count', \n",
    "    'best_score': 'avg_best_score'\n",
    "}, inplace=True)\n",
    "\n",
    "# Create a new 'popularity' score, possibly weighted\n",
    "agg_data['popularity'] = agg_data['avg_stars'] * 0.5 + agg_data['comment_count'] * 0.3 + agg_data['avg_best_score'] * 0.2\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(agg_data[['avg_stars', 'comment_count', 'avg_best_score']])\n",
    "y = agg_data['popularity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Deep Learning Model (Starter Code)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def build_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, input_dim=input_dim, activation='relu'),  # ReLU activation function for hidden layer\n",
    "        Dropout(0.2),  # Dropout for regularization\n",
    "        Dense(64, activation='relu'),  # Another hidden layer\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='linear')  # Linear activation for a regression output\n",
    "    ])\n",
    "    # Compile the model with an optimizer and loss function\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "# Instantiate and train the model\n",
    "model = build_model(X_train.shape[1])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32)\n",
    "\n",
    "# Step 8: Model Evaluation\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "print(\"\\nMean Absolute Error (MAE):\")\n",
    "print(mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   recipe_code     100 non-null    int64  \n",
      " 1   avg_stars       100 non-null    float64\n",
      " 2   comment_count   100 non-null    int64  \n",
      " 3   avg_best_score  100 non-null    float64\n",
      " 4   popularity      100 non-null    float64\n",
      "dtypes: float64(3), int64(2)\n",
      "memory usage: 4.0 KB\n"
     ]
    }
   ],
   "source": [
    "agg_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recipe_code       0\n",
       "avg_stars         0\n",
       "comment_count     0\n",
       "avg_best_score    0\n",
       "popularity        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping variables\n",
    "agg_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_code</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>avg_best_score</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>386</td>\n",
       "      <td>4.290179</td>\n",
       "      <td>224</td>\n",
       "      <td>167.714286</td>\n",
       "      <td>102.887946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>414</td>\n",
       "      <td>4.179641</td>\n",
       "      <td>167</td>\n",
       "      <td>198.958084</td>\n",
       "      <td>91.981437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>957</td>\n",
       "      <td>4.303318</td>\n",
       "      <td>211</td>\n",
       "      <td>139.559242</td>\n",
       "      <td>93.363507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1063</td>\n",
       "      <td>4.493671</td>\n",
       "      <td>158</td>\n",
       "      <td>135.341772</td>\n",
       "      <td>76.715190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081</td>\n",
       "      <td>4.141892</td>\n",
       "      <td>148</td>\n",
       "      <td>129.216216</td>\n",
       "      <td>72.314189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>74724</td>\n",
       "      <td>4.224490</td>\n",
       "      <td>147</td>\n",
       "      <td>118.734694</td>\n",
       "      <td>69.959184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>82745</td>\n",
       "      <td>4.369748</td>\n",
       "      <td>119</td>\n",
       "      <td>208.865546</td>\n",
       "      <td>79.657983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>100276</td>\n",
       "      <td>4.317073</td>\n",
       "      <td>164</td>\n",
       "      <td>161.817073</td>\n",
       "      <td>83.721951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>141947</td>\n",
       "      <td>4.570175</td>\n",
       "      <td>114</td>\n",
       "      <td>219.684211</td>\n",
       "      <td>80.421930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>191775</td>\n",
       "      <td>4.258929</td>\n",
       "      <td>112</td>\n",
       "      <td>188.821429</td>\n",
       "      <td>73.493750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    recipe_code  avg_stars  comment_count  avg_best_score  popularity\n",
       "0           386   4.290179            224      167.714286  102.887946\n",
       "1           414   4.179641            167      198.958084   91.981437\n",
       "2           957   4.303318            211      139.559242   93.363507\n",
       "3          1063   4.493671            158      135.341772   76.715190\n",
       "4          1081   4.141892            148      129.216216   72.314189\n",
       "..          ...        ...            ...             ...         ...\n",
       "95        74724   4.224490            147      118.734694   69.959184\n",
       "96        82745   4.369748            119      208.865546   79.657983\n",
       "97       100276   4.317073            164      161.817073   83.721951\n",
       "98       141947   4.570175            114      219.684211   80.421930\n",
       "99       191775   4.258929            112      188.821429   73.493750\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_code</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>avg_best_score</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24356.350000</td>\n",
       "      <td>4.252851</td>\n",
       "      <td>181.820000</td>\n",
       "      <td>156.193806</td>\n",
       "      <td>87.911186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27500.396712</td>\n",
       "      <td>0.324980</td>\n",
       "      <td>106.803641</td>\n",
       "      <td>33.641169</td>\n",
       "      <td>31.738382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>386.000000</td>\n",
       "      <td>2.614973</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>105.514019</td>\n",
       "      <td>48.309677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7741.000000</td>\n",
       "      <td>4.098373</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>131.082339</td>\n",
       "      <td>70.803335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17568.000000</td>\n",
       "      <td>4.317320</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>148.432197</td>\n",
       "      <td>81.864039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33894.000000</td>\n",
       "      <td>4.455943</td>\n",
       "      <td>191.750000</td>\n",
       "      <td>178.319126</td>\n",
       "      <td>93.020289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>191775.000000</td>\n",
       "      <td>4.731343</td>\n",
       "      <td>725.000000</td>\n",
       "      <td>253.015748</td>\n",
       "      <td>247.060828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         recipe_code   avg_stars  comment_count  avg_best_score  popularity\n",
       "count     100.000000  100.000000     100.000000      100.000000  100.000000\n",
       "mean    24356.350000    4.252851     181.820000      156.193806   87.911186\n",
       "std     27500.396712    0.324980     106.803641       33.641169   31.738382\n",
       "min       386.000000    2.614973      31.000000      105.514019   48.309677\n",
       "25%      7741.000000    4.098373     128.000000      131.082339   70.803335\n",
       "50%     17568.000000    4.317320     149.000000      148.432197   81.864039\n",
       "75%     33894.000000    4.455943     191.750000      178.319126   93.020289\n",
       "max    191775.000000    4.731343     725.000000      253.015748  247.060828"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   popularity popularity_bin\n",
      "0  102.887946              2\n",
      "1   91.981437              1\n",
      "2   93.363507              2\n",
      "3   76.715190              1\n",
      "4   72.314189              1\n"
     ]
    }
   ],
   "source": [
    "# Define bin edges based on min, percentiles, and max\n",
    "bin_edges = [agg_data['popularity'].min(), 70.803335, 93.020289, agg_data['popularity'].max()]\n",
    "bin_labels = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Bin the popularity scores into Low, Medium, and High categories\n",
    "agg_data['popularity_bin'] = pd.cut(agg_data['popularity'], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Convert the bins to numeric for modeling (Low=0, Medium=1, High=2)\n",
    "agg_data['popularity_bin'] = agg_data['popularity_bin'].map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "\n",
    "# Print to verify the binning\n",
    "print(agg_data[['popularity', 'popularity_bin']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 129 is out of bounds for axis 1 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     10\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m     11\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Stop training after 3 epochs of no improvement\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Restore the best weights after training\u001b[39;00m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the labels to one-hot encoding\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m y_train_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m y_test_encoded \u001b[38;5;241m=\u001b[39m to_categorical(y_test, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Define the RNN model for multi-class classification\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\numerical_utils.py:99\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(x, num_classes)\u001b[0m\n\u001b[0;32m     97\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     98\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, num_classes))\n\u001b[1;32m---> 99\u001b[0m \u001b[43mcategorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    100\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[0;32m    101\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 129 is out of bounds for axis 1 with size 3"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define EarlyStopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,  # Stop training after 3 epochs of no improvement\n",
    "    restore_best_weights=True  # Restore the best weights after training\n",
    ")\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train, num_classes=3)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Define the RNN model for multi-class classification\n",
    "def build_rnn_model(input_dim, input_length):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=10000, output_dim=128, input_length=input_length),  # Embedding layer\n",
    "        LSTM(64, return_sequences=False),  # LSTM layer\n",
    "        Dropout(0.5),  # Dropout for regularization\n",
    "        Dense(32, activation='relu'),  # Fully connected layer\n",
    "        BatchNormalization(),  # Batch normalization\n",
    "        Dense(3, activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',  # Multi-class classification loss\n",
    "        metrics=['accuracy']  # Accuracy metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Build the RNN model\n",
    "input_length = X_train.shape[1]  # Number of input features\n",
    "rnn_model = build_rnn_model(input_dim=10000, input_length=input_length)\n",
    "\n",
    "# Train the model\n",
    "history = rnn_model.fit(\n",
    "    X_train, y_train_encoded,  # Ensure X_train is numerical and y_train_encoded is one-hot encoded\n",
    "    validation_data=(X_test, y_test_encoded),  # Validation set\n",
    "    epochs=10,  # Adjust as needed\n",
    "    batch_size=32,  # Adjust based on dataset size\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = rnn_model.predict(X_test)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Low', 'Medium', 'High']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popularity_bin\n",
      "1    50\n",
      "0    25\n",
      "2    25\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(agg_data['popularity_bin'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct binning logic if needed\n",
    "bin_edges = [agg_data['popularity'].min(), 70.803335, 93.020289, agg_data['popularity'].max()]\n",
    "bin_labels = ['Low', 'Medium', 'High']\n",
    "agg_data['popularity_bin'] = pd.cut(agg_data['popularity'], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "agg_data['popularity_bin'] = agg_data['popularity_bin'].map({'Low': 0, 'Medium': 1, 'High': 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = agg_data[['avg_stars', 'comment_count', 'avg_best_score']].values\n",
    "y = agg_data['popularity_bin'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = to_categorical(y_train, num_classes=3)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etiem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - accuracy: 0.3891 - loss: 1.1187 - val_accuracy: 0.5000 - val_loss: 1.0963\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4547 - loss: 1.0427 - val_accuracy: 0.5000 - val_loss: 1.0934\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5391 - loss: 0.9747 - val_accuracy: 0.5000 - val_loss: 1.0911\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6828 - loss: 0.8894 - val_accuracy: 0.5000 - val_loss: 1.0885\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7336 - loss: 0.8102 - val_accuracy: 0.5000 - val_loss: 1.0864\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8461 - loss: 0.7287 - val_accuracy: 0.5000 - val_loss: 1.0841\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7484 - loss: 0.7668 - val_accuracy: 0.5000 - val_loss: 1.0817\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8047 - loss: 0.5939 - val_accuracy: 0.5000 - val_loss: 1.0790\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8406 - loss: 0.5265 - val_accuracy: 0.5000 - val_loss: 1.0757\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8820 - loss: 0.4618 - val_accuracy: 0.5000 - val_loss: 1.0723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.00      0.00      0.00         5\n",
      "      Medium       0.50      1.00      0.67        10\n",
      "        High       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.17      0.33      0.22        20\n",
      "weighted avg       0.25      0.50      0.33        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etiem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\etiem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\etiem\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define EarlyStopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,  # Stop training after 3 epochs of no improvement\n",
    "    restore_best_weights=True  # Restore the best weights after training\n",
    ")\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train_encoded = to_categorical(y_train, num_classes=3)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "# Define the RNN model for multi-class classification\n",
    "def build_rnn_model(input_dim, input_length):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=10000, output_dim=128, input_length=input_length),  # Embedding layer\n",
    "        LSTM(64, return_sequences=False),  # LSTM layer\n",
    "        Dropout(0.5),  # Dropout for regularization\n",
    "        Dense(32, activation='relu'),  # Fully connected layer\n",
    "        BatchNormalization(),  # Batch normalization\n",
    "        Dense(3, activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',  # Multi-class classification loss\n",
    "        metrics=['accuracy']  # Accuracy metric\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Build the RNN model\n",
    "input_length = X_train.shape[1]  # Number of input features\n",
    "rnn_model = build_rnn_model(input_dim=10000, input_length=input_length)\n",
    "\n",
    "# Train the model\n",
    "history = rnn_model.fit(\n",
    "    X_train, y_train_encoded,  # Ensure X_train is numerical and y_train_encoded is one-hot encoded\n",
    "    validation_data=(X_test, y_test_encoded),  # Validation set\n",
    "    epochs=10,  # Adjust as needed\n",
    "    batch_size=32,  # Adjust based on dataset size\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_probs = rnn_model.predict(X_test)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Low', 'Medium', 'High']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
